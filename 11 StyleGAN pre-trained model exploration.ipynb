{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11 StyleGAN pre-trained model exploration.ipynb","provenance":[{"file_id":"https://github.com/https-deeplearning-ai/GANs-Public/blob/master/C1W1_(Colab)_Pre_trained_model_exploration.ipynb","timestamp":1602245466822}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"52p13PdIIGNF"},"source":["## StyleGAN - faces\n","\n","#### Run the generative model called StyleGAN to generate fake faces.\n","\n","You are going to use the original paper's implementation of StyleGAN. ( https://arxiv.org/pdf/1812.04948.pdf )"]},{"cell_type":"code","metadata":{"id":"rPPQoVcDH_qr","executionInfo":{"status":"ok","timestamp":1604049046443,"user_tz":-480,"elapsed":2703,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"9ab75698-7c3f-4459-a5e2-035eb95460ff","colab":{"base_uri":"https://localhost:8080/"}},"source":["!git clone https://github.com/NVlabs/stylegan.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'stylegan'...\n","remote: Enumerating objects: 83, done.\u001b[K\n","remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n","Unpacking objects: 100% (83/83), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AM12Bh9620dZ","executionInfo":{"status":"ok","timestamp":1604049053286,"user_tz":-480,"elapsed":8980,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"8902f6a5-f51d-4334-9225-94690ee32716","colab":{"base_uri":"https://localhost:8080/"}},"source":["%tensorflow_version 1.x\n","# Import needed Python libraries\n","import os\n","import pickle\n","import warnings\n","import numpy as np\n","import PIL\n","\n","from tensorflow.python.util import module_wrapper\n","module_wrapper._PER_MODULE_WARNING_LIMIT = 0\n","\n","# Import the official StyleGAN repo\n","import stylegan\n","from stylegan.dnnlib import tflib\n","from stylegan import config\n","\n","# Initialize TensorFlow\n","tflib.init_tf()\n","\n","# Move into the StyleGAN directory, if you're not in it already\n","path = 'stylegan/'\n","if \"stylegan\" not in os.getcwd():\n","    os.chdir(path)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NnAV8iSO7Asa","cellView":"both","executionInfo":{"status":"ok","timestamp":1604049079302,"user_tz":-480,"elapsed":32946,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"4fb7f63d-b6e0-4196-c09f-546dd963409c","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Load pre-trained StyleGAN network\n","url = 'https://bitbucket.org/ezelikman/gans/downloads/karras2019stylegan-ffhq-1024x1024.pkl' # karras2019stylegan-ffhq-1024x1024.pkl\n","with stylegan.dnnlib.util.open_url(url, cache_dir=stylegan.config.cache_dir) as f:\n","  # You'll load 3 components, and use the last one Gs for sampling images.\n","  #   _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n","  #   _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n","  #   Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n","  _G, _D, Gs = pickle.load(f)\n","\n","  print('StyleGAN package loaded successfully!')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading https://bitbucket.org/ezelikman/gans/downloads/karras2019stylegan-ffhq-1024x1024.pkl ... done\n","WARNING:tensorflow:From <string>:364: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","StyleGAN package loaded successfully!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kqndkx1SEEfo","cellView":"form","executionInfo":{"status":"ok","timestamp":1604049080412,"user_tz":-480,"elapsed":1090,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"45aac986-cb48-40d8-c719-d36627c7924f","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@title Generate faces with StyleGAN\n","#@markdown Double click here to see the code. After setting truncation, run the cells below to generate images. This adjusts the truncation, truncation trades off fidelity (quality) and diversity of the generated images - play with it!  \n","\n","#@markdown `truncation`: The positive truncation value. 1 is low truncation (high diversity) and 0 is all truncation except for the mean (high quality/fidelity). A lower value increases fidelity and decreases diversity, and vice versa. These are trade-offs that you can play with.\n","\n","Truncation = 0.2 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","print(f'Truncation set to {Truncation}. \\nNow run the cells below to generate images with this truncation value.')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Truncation set to 0.2. \n","Now run the cells below to generate images with this truncation value.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iq0Y4hhMLput","executionInfo":{"status":"ok","timestamp":1604049080413,"user_tz":-480,"elapsed":1082,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"2e7515d9-9891-4a88-d78c-2a0432d6217f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Set the random state. Nothing special about 24\n","rnd = np.random.RandomState(24)\n","\n","print(f'Random state is set.')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Random state is set.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SyYKbSjGaoPW"},"source":["You'll default to 4 images for the run, which is called a batch. Feel free to generate more by changing this parameter, but note that very large batch sizes will cause the model to run out of memory."]},{"cell_type":"code","metadata":{"id":"RKeYEq2ULtXM","cellView":"form","executionInfo":{"status":"ok","timestamp":1604049080414,"user_tz":-480,"elapsed":1075,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"d96b2147-f6a6-40cc-9814-49503b05f645","colab":{"base_uri":"https://localhost:8080/"}},"source":["batch_size = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n","\n","print(f'Batch size is {batch_size}...')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Batch size is 4...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-CHZHltvWdiu"},"source":["Noise vectors make sure the generated images are randomly (stochastically) different, not all the same. Notice that there is a noise vector for each image in the batch. You can run this next cell as many times as you want to get new noise vectors, and as a result, new images!"]},{"cell_type":"code","metadata":{"id":"ADIQll1SL176","executionInfo":{"status":"ok","timestamp":1604049080415,"user_tz":-480,"elapsed":1069,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"5cf84003-19b3-4506-c326-7f0319c122b5","colab":{"base_uri":"https://localhost:8080/"}},"source":["input_shape = Gs.input_shape[1]\n","noise_vectors = rnd.randn(batch_size, input_shape)\n","\n","print(f'There are {noise_vectors.shape[0]} noise vectors, each with {noise_vectors.shape[1]} random values between -{Truncation} and {Truncation}.')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["There are 4 noise vectors, each with 512 random values between -0.2 and 0.2.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cNylJxh8fyGn"},"source":["Run the model to generate the images. \n","\n","Notice that truncation and noise vectors are passed in. Don't worry too much about the other stuff - it's about output formats and adding additional randomness/diversity to the output."]},{"cell_type":"code","metadata":{"id":"kY_sFRprM_35","executionInfo":{"status":"ok","timestamp":1604049090397,"user_tz":-480,"elapsed":11043,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"3483e1b4-b511-4863-c282-ba1913c154e0","colab":{"base_uri":"https://localhost:8080/"}},"source":["fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","images = Gs.run(noise_vectors, None, truncation_psi=Truncation, randomize_noise=False, output_transform=fmt)\n","\n","print(f'Successfully sampled {batch_size} images from the model.')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Successfully sampled 4 images from the model.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0XJYv_XlW96b"},"source":["Now you save and visualize the images. Feel free to regenerate the noise vectors above and run the cells afterwards to see new images. "]},{"cell_type":"code","metadata":{"id":"g-6GOkdaLNXa","executionInfo":{"status":"ok","timestamp":1604049114761,"user_tz":-480,"elapsed":35401,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"a1ca7446-fd26-4b11-deb1-1d19014790a4","colab":{"base_uri":"https://localhost:8080/","height":273,"output_embedded_package_id":"1DuqZg7P8qQtOnFqOsstF9EzKYxthgWhx"}},"source":["# Save the images\n","os.makedirs(config.result_dir, exist_ok=True)\n","png_filename = os.path.join(config.result_dir, 'stylegan-example.png')\n","if batch_size > 1:\n","  img = np.concatenate(images, axis=1)\n","else:\n","  img = images[0]\n","PIL.Image.fromarray(img, 'RGB').save(png_filename)\n","\n","# Check the images out!\n","from IPython.display import Image\n","Image(png_filename, width=256*batch_size, height=256)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"bUEi4iq-v2jl"},"source":["Here's another script to help familiarize you with what interpolation in GANs can look likeâ€”filling in the unknown between two objects. In this case, you are using face images where the GAN will fill in how one image can morph into another. You will generate random noise vectors for the start and end images and then create noise vectors for the the ones inbetween.\n","\n","Again, feel free to mess with any of the code but here are some values you should try modifying:\n","  *   `rnd`: The random seed that generates the noise vectors. Changing this will change the noise vectors fed to the generator and, consequently, the images generated!\n","  *   `truncation`: The truncation value between 0 and 1. 1 is no truncation (high diversity) and 0 is all truncation except for the mean (high quality/fidelity). A lower value increases fidelity and decreases diversity, and vice versa. These are trade-offs that you can play with.\n","  *   `n_interpolations`: The number of images that you want generated. A 3 would mean there is one transition photo between the start and end photos. If you want to see an interpolation, this value should be greater than 2."]},{"cell_type":"code","metadata":{"id":"fIGUouKiv3R3","executionInfo":{"status":"ok","timestamp":1604049167707,"user_tz":-480,"elapsed":32573,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"60390720-4219-4817-eeb6-4b9de52183c7","colab":{"base_uri":"https://localhost:8080/","height":240,"output_embedded_package_id":"1FuDi2B5fbGwx7tBriCzA8_t2TdKkjNUy"}},"source":["# Set the random seed that generates the noise vectors\n","rnd = np.random.RandomState(24)\n","\n","# Set the truncation value for truncation trick sampling\n","truncation = 0.2\n","\n","# Set the number of interpolations/number of images to generate\n","n_interpolation = 5\n","\n","# Create a noise vector z for the start and end images (batch_size = 1 since they are single image): (batch_size, z_dim)\n","# And create noise for the interpolations inbetween\n","z_dim = Gs.input_shape[1]\n","first_noise = rnd.randn(1, z_dim)\n","second_noise = rnd.randn(1, z_dim)\n","percent_first_noise = np.linspace(0, 1, n_interpolation)[:, None]\n","interpolation_noise = first_noise * percent_first_noise + second_noise * (1 - percent_first_noise)\n","\n","# Generate image by running (sampling) the generator\n","fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True) # Specify the desired output format and shape\n","images = Gs.run(interpolation_noise,\n","                None,    # No labels/conditions because it is unconditional generation!\n","                truncation_psi=truncation, \n","                randomize_noise=False,\n","                output_transform=fmt\n","                )\n","\n","# Display images\n","if batch_size > 1:\n","  img = np.concatenate(images, axis=1) # Save all images in batch to a single image\n","else:\n","  img = images[0]\n","PIL.Image.fromarray(img, 'RGB')"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}